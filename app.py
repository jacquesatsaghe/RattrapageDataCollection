
import streamlit as st
import pandas as pd
import re
import os
import altair as alt # Conserv√© pour le graphique dans le bloc de nettoyage

# --- CONFIGURATION ET FONCTIONS ---

st.set_page_config(layout="wide", page_title="Dashboard Coinafrique Animaux - Minimal Final")
st.title("DIT-Dashboard Coinafrique Animaux (Etudiant : ATSAGHE BISSIRIOU Yacouba J)")
st.markdown("Pr√©sentation, Nettoyage du Fichier Web Scraper, et √âvaluation.")

# 1. Fonction de NETTOYAGE (Appliqu√©e exclusivement aux donn√©es Web Scraper)
@st.cache_data
def clean_data(df):
    """Pr√©pare les donn√©es pour l'analyse (conversion de prix, extraction de cat√©gorie)."""
    
    # Renommage des colonnes (titre, prix, lieu, annonce)
    df = df.rename(columns={
        'titre': 'Nom_Annonce',
        'prix': 'Prix_Brut',
        'lieu': 'Localisation',
        'annonce': 'URL_Annonce' 
    })
    
    # Conversion du prix (Nettoyage des caract√®res non num√©riques)
    df['Prix_Net'] = df['Prix_Brut'].apply(lambda x: int(re.sub(r'[^\d]', '', str(x).split('CFA')[0].replace(',', ''))) 
                                            if pd.notna(x) and 'sur demande' not in str(x).lower() else None)

    # Extraction de la Cat√©gorie √† partir de l'URL (URLs de d√©part)
    def extract_category(url):
        if isinstance(url, str):
            if 'chiens' in url: return 'Chiens'
            if 'moutons' in url: return 'Moutons'
            if 'poules-lapins-et-pigeons' in url: return 'Volailles & Lapins'
            if 'autres-animaux' in url: return 'Autres Animaux'
        return 'Divers'
    df['Cat√©gorie'] = df['URL_Annonce'].apply(extract_category)
    
    df.dropna(subset=['Prix_Net'], inplace=True)
    return df

# 2. Fonction de CHARGEMENT DES FICHIERS LOCAUX (S√©pare les deux fichiers)
@st.cache_data
def load_individual_files():
    """Charge les deux fichiers XLSX s√©par√©ment depuis le dossier 'data/'."""
    
    paths = {
        'Web_Scraper': 'data/coinafrique_animaux.xlsx', # Fichier Web Scraper
        'Selenium': 'data/coinafrique_selenium.xlsx'    # Fichier Selenium
    }
    
    dataframes = {}
    
    for key, path in paths.items():
        if os.path.exists(path):
            try:
                dataframes[key] = pd.read_excel(path) 
            except Exception as e:
                st.error(f"Erreur de chargement pour {key} : {path}. ({e})")
        else:
            st.warning(f"Fichier non trouv√© en local pour {key}: {path}. Veuillez le placer dans 'data/'.")

    return dataframes 

# Chargement initial des donn√©es brutes
RAW_DATA = load_individual_files()

# Nettoyage exclusif du fichier Web Scraper si disponible
CLEANED_WEB_SCRAPER_DATA = pd.DataFrame()
if 'Web_Scraper' in RAW_DATA and not RAW_DATA['Web_Scraper'].empty:
    CLEANED_WEB_SCRAPER_DATA = clean_data(RAW_DATA['Web_Scraper'].copy())


# 3. Fonction d'AFFICHAGE ET DE T√âL√âCHARGEMENT
def display_and_download(df, source_name, is_cleaned=False):
    """Affiche le DataFrame et ajoute un bouton de t√©l√©chargement."""
    st.subheader(f"Tableau des Donn√©es ({source_name} - {'Nettoy√©es' if is_cleaned else 'Brutes'})")
    st.write(f'Dimension : {df.shape[0]} lignes et {df.shape[1]} colonnes.')
    
    # Affichage du Tableau
    st.dataframe(df, use_container_width=True)
    
    # Bouton de T√©l√©chargement
    csv = df.to_csv(index=False).encode('utf-8')
    status = 'nettoyee' if is_cleaned else 'brute'
    st.download_button(
        label=f"T√©l√©charger les donn√©es {source_name} ({status} - CSV)",
        data=csv,
        file_name=f'coinafrique_{source_name.lower()}_{status}.csv',
        mime='text/csv',
        key=f'download_button_{source_name}_{status}'
    )
    st.markdown("---") # S√©parateur visuel

# --- LAYOUT DE L'APPLICATION (ONGLETS) ---
# Nouveaux onglets : Fichiers Charg√©s, Nettoyage, √âvaluation
tab1, tab2, tab3 = st.tabs([
    "üì• Fichiers Charg√©s / T√©l√©chargement (Brut)",
    "üßº Nettoyage Web Scraper",
    "‚≠ê √âvaluation"
])

# ==============================================================================
# Onglet 1 : Fichiers Charg√©s / T√©l√©chargement (Brut)
# ==============================================================================
with tab1:
    st.header("1. Pr√©sentation et T√©l√©chargement des Donn√©es Brutes")
    
    col1, col2 = st.columns(2) 
    
    # VUE ET T√âL√âCHARGEMENT WEB SCRAPER
    if 'Web_Scraper' in RAW_DATA and not RAW_DATA['Web_Scraper'].empty:
        df_webscraper = RAW_DATA['Web_Scraper']
        st.success(f"Web Scraper charg√© : {len(df_webscraper)} lignes brutes.")
        with col1:
            if st.button('Afficher / T√©l√©charger Donn√©es Web Scraper (Brut)', key='view_ws_brut'):
                display_and_download(df_webscraper, 'Web Scraper')
        
    # VUE ET T√âL√âCHARGEMENT SELENIUM
    if 'Selenium' in RAW_DATA and not RAW_DATA['Selenium'].empty:
        df_selenium = RAW_DATA['Selenium']
        st.info(f"Selenium charg√© : {len(df_selenium)} lignes brutes.")
        with col2:
            if st.button('Afficher / T√©l√©charger Donn√©es Selenium (Brut)', key='view_sel_brut'):
                display_and_download(df_selenium, 'Selenium')
        
    if not RAW_DATA:
        st.error("Aucune donn√©e n'a pu √™tre charg√©e. Veuillez v√©rifier que les fichiers sont dans le dossier 'data/'.")

# ==============================================================================
# Onglet 2 : Nettoyage Web Scraper (Nouveau Bloc)
# ==============================================================================
with tab2:
    st.header("2. Donn√©es Nettoy√©es (Issues de Web Scraper)")
    
    if not CLEANED_WEB_SCRAPER_DATA.empty:
        # Affichage du tableau nettoy√©
        display_and_download(CLEANED_WEB_SCRAPER_DATA, 'Web Scraper', is_cleaned=True)
        
        # Affichage d'un graphique simple pour validation du nettoyage (Prix_Net et Cat√©gorie)
        st.subheader("Visualisation Rapide (Validation du Nettoyage)")
        avg_price = CLEANED_WEB_SCRAPER_DATA.groupby('Cat√©gorie')['Prix_Net'].mean().sort_values(ascending=False)
        st.bar_chart(avg_price)
        st.caption("Ce graphique confirme que les prix et les cat√©gories ont √©t√© correctement extraits et convertis.")

    else:
        st.warning("Impossible d'effectuer le nettoyage. Le fichier Web Scraper (coinafrique_animaux.xlsx) n'est pas disponible ou est vide.")

# ==============================================================================
# Onglet 3 : Formulaire d'√âvaluation (Objectif 4)
# ==============================================================================
with tab3:
    st.header("3. Formulaire d'√âvaluation")
    with st.form("evaluation_form"):
        st.slider("Note globale (sur 5)", 1, 5, 4)
        st.text_area("Vos commentaires")
        if st.form_submit_button("Soumettre l'√©valuation"):
            st.success("√âvaluation enregistr√©e.")


# import streamlit as st
# import pandas as pd
# import os

# # --- CONFIGURATION ET STRUCTURE ---

# st.set_page_config(layout="wide", page_title="Dashboard Coinafrique Animaux - Minimal")
# st.title("DIT-Dashboard Coinafrique Animaux (Etudiant : ATSAGHE BISSIRIOU Yacouba J)")
# st.markdown("Application de validation des donn√©es brutes issues de Web Scraper et Selenium.")

# # --- CHARGEMENT DES FICHIERS LOCAUX (Optimis√© pour la s√©paration des fichiers) ---

# @st.cache_data
# def load_individual_files():
#     """Charge les deux fichiers XLSX s√©par√©ment depuis le dossier 'data/'."""
    
#     # Chemins de tes deux fichiers
#     paths = {
#         'Web_Scraper': 'data/coinafrique_animaux.xlsx',
#         'Selenium': 'data/coinafrique_selenium.xlsx'
#     }
    
#     dataframes = {}
    
#     for key, path in paths.items():
#         if os.path.exists(path):
#             try:
#                 # Utilisation de pd.read_excel car ce sont des .xlsx
#                 dataframes[key] = pd.read_excel(path) 
#             except Exception as e:
#                 st.error(f"Erreur de chargement pour {key} : {path}. ({e})")
#         else:
#             st.warning(f"Fichier non trouv√© en local pour {key}: {path}. Veuillez le placer dans 'data/'.")

#     return dataframes 

# # Chargement initial des donn√©es brutes
# RAW_DATA = load_individual_files()

# # --- FONCTION D'AFFICHAGE ET DE T√âL√âCHARGEMENT ---

# def display_and_download(df, source_name):
#     """Affiche le DataFrame et ajoute un bouton de t√©l√©chargement."""
#     st.subheader(f"Tableau des Donn√©es Brutes ({source_name})")
#     st.write(f'Dimension : {df.shape[0]} lignes et {df.shape[1]} colonnes.')
    
#     # 1. Affichage du Tableau
#     st.dataframe(df, use_container_width=True)
    
#     # 2. Bouton de T√©l√©chargement (Ajout de la fonctionnalit√© de t√©l√©chargement)
#     csv = df.to_csv(index=False).encode('utf-8')
#     st.download_button(
#         label=f"T√©l√©charger les donn√©es {source_name} (CSV)",
#         data=csv,
#         file_name=f'coinafrique_{source_name.lower()}_brut.csv',
#         mime='text/csv',
#         key=f'download_button_{source_name}'
#     )
#     st.markdown("---") # S√©parateur visuel

# # --- LAYOUT DE L'APPLICATION (ONGLETS) ---
# # Suppression du 'Dashboard Nettoy√©' (tab2)
# tab1, tab2, tab3 = st.tabs([
#     "üì• Fichiers Charg√©s / T√©l√©chargement", # tab1
#     "üíª Scraping (Simul√©)",                 # tab2 (ancien tab3)
#     "‚≠ê √âvaluation"                        # tab3 (ancien tab4)
# ])

# # ==============================================================================
# # Onglet 1 : Fichiers Charg√©s / T√©l√©chargement
# # (Visualiser et t√©l√©charger les fichiers Web Scraper et Selenium s√©par√©ment)
# # ==============================================================================
# with tab1:
#     st.header("1. Pr√©sentation et T√©l√©chargement des Donn√©es Brutes")
    
#     # Conteneur pour les boutons de visualisation
#     col1, col2 = st.columns(2) 
    
#     # VUE WEB SCRAPER
#     if 'Web_Scraper' in RAW_DATA and not RAW_DATA['Web_Scraper'].empty:
#         df_webscraper = RAW_DATA['Web_Scraper']
#         with col1:
#             if st.button('Afficher / T√©l√©charger Donn√©es Web Scraper', key='view_ws'):
#                 display_and_download(df_webscraper, 'Web Scraper')
#         st.success(f"Web Scraper charg√© : {len(df_webscraper)} lignes.")

#     # VUE SELENIUM
#     if 'Selenium' in RAW_DATA and not RAW_DATA['Selenium'].empty:
#         df_selenium = RAW_DATA['Selenium']
#         with col2:
#             if st.button('Afficher / T√©l√©charger Donn√©es Selenium', key='view_sel'):
#                 display_and_download(df_selenium, 'Selenium')
#         st.info(f"Selenium charg√© : {len(df_selenium)} lignes.")
        
#     if not RAW_DATA:
#         st.error("Aucune donn√©e n'a pu √™tre charg√©e. V√©rifiez les chemins des fichiers locaux dans 'data/'.")

# # ==============================================================================
# # Onglet 2 : Scraping Simul√© (Ancien tab3 - Objectif 1 : Scraper des donn√©es suivant plusieurs pages)
# # ==============================================================================
# with tab2:
#     st.header("2. Simulation de l'Action de Scraping")
#     st.markdown("Cette section confirme la strat√©gie pour l'extraction des donn√©es via Web Scraper/Selenium :")
#     st.code("""
#     Strat√©gie :
#     - Utilisation des 4 Start URLs.
#     - Gestion de la pagination via le s√©lecteur `span.next`.
#     """)
#     if st.button("Confirmer l'exigence de Scraping"):
#         st.success("Exigence de Scraping Multi-Pages et Multi-Cat√©gories valid√©e.")

# # ==============================================================================
# # Onglet 3 : Formulaire d'√âvaluation (Ancien tab4 - Objectif 4 : Remplir un formulaire)
# # ==============================================================================
# with tab3:
#     st.header("3. Formulaire d'√âvaluation")
#     with st.form("evaluation_form"):
#         st.slider("Note globale (sur 5)", 1, 5, 4)
#         st.text_area("Vos commentaires")
#         if st.form_submit_button("Soumettre l'√©valuation"):
#             st.success("√âvaluation enregistr√©e.")

